{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Recurrent Neural Network\n",
    "- Mimicing Linux code style\n",
    "- Gated Recurrent Unit(GRU)\n",
    "\n",
    "![alt text](./GRU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "embedding_size = 150\n",
    "hidden_size = 100\n",
    "batch_size =1\n",
    "num_layers = 2\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "### 1) Prepare characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 33756\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./data/linux.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions for text processing\n",
    "### 1) Random Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " val > BFQ_MAX_WEIGHT)\n",
      "\t\treturn ret;\n",
      "\n",
      "\tret = 0;\n",
      "\tspin_lock_irq(&blkcg->lock);\n",
      "\tbfqgd->weight = (unsigned short)val;\n",
      "\thlist_for_each_entry(blkg, &blkcg->blkg_list, blkcg_node) {\n",
      "\t\tstruct bfq_group *bfqg\n"
     ]
    }
   ],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Character to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      " 37\n",
      " 38\n",
      " 13\n",
      " 14\n",
      " 15\n",
      "[torch.LongTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)#.cuda()\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Chunk into input & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer\n",
    "\n",
    "![alt text](./gru_ex.jpg)\n",
    "\n",
    "\n",
    "### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size,embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.GRU(embedding_size,hidden_size,num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,hidden = self.rnn(out,hidden)\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        \n",
    "        return out,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(num_layers, batch_size, hidden_size))#.cuda()\n",
    "        return hidden\n",
    "    \n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "torch.Size([2, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out,hidden = model(inp,hidden)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    x = inp\n",
    "\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(200):\n",
    "        output,hidden = model(x,hidden)\n",
    "\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "\n",
    "        print(predicted_char,end=\"\")\n",
    "\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Variable containing:\n",
      " 4.5846\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bm$?'Rl`EskmE)C\u000b",
      "htPTc9z$J^80J'F3D{)W>UU'~79zq`\\o.@fYO\n",
      "Bi)6K\"5(gj\"_h3NB##hI{\\~;NeD[keg4Vodx\u000b",
      "'E(Zni|v4s{8N@j%(N>mXd)T!LkWU=eqry/3f*e$@.2eY}L|#:[*>M!=`yzb@\tZXb Y,t4s=bWEcW>:I1(\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.6430\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "g_so;\n",
      "\tblkg_nIg_se\n",
      "\t\tse bfqg);\n",
      "{\n",
      "\t{\n",
      "\t{\t\t\t\t\tXq_crectoit (et blkg\t\tst ohe(stum, dime\n",
      " *ets_lere|\n",
      "\t\t\t\t\t\t\t\t\t\t/G\n",
      "\t *sta prarlveit = bqg_vessrunse_satoig *cscste_tielt = steruct blkg_sfeleet_troruec blkg_s\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.7550\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg);\n",
      "\tret tat *bfq_groux_bfqg, io\n",
      "\t\t\t * tinveq_vericy,\n",
      "\t\t * blkcg, bfqg = kseed the tho\n",
      "\tbfqd_setuume ity\n",
      "\t * sterntsith * ci = = bfq_set fice->stats = bfqg->stimed(structic bfq_daty_stime)>stats ofe\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9764\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_rstats *bfqg))\n",
      "\t}-q_sers = *bfqg->stats_nstruct bfqg->flocp_time,\n",
      "\t\t\t\t * *struct bfqg_print_recurssive_sest_ivad;\n",
      "\tstruct to the pd_free *bfqg_cthate *bfq, bfqg->queue->ampd(&statsig, aelses cooti\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.3849\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_cpat_add_aux(&Ko_bfqg->entity_graatex(&time);\n",
      "\t\tret_stats.\n",
      "\t\t     bilr/ oundet tis->amgroup *bfqg);\n",
      "\n",
      "with the bfqg_stats->ave. *stats->idlicy_datat_reset(&struct bfqg_stat_restat_reset(&to->mert(&\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.4435\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats_malk_owe_condi_add_stats_lock();\n",
      "\tblkg->blkg_policy_data = blkcg(pd)\n",
      "{\n",
      "\tstruct bfqg = bfq_group *bfqg(bic_ctime, ass\n",
      "\t * as oing of ok);\n",
      "\tif (ouptime = );\n",
      "\tif (bfqg_parint_to_bfqd, bfq_get_c\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.7585\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_policy_pririate *stats->idle *stats-ketentity->weight\n",
      "\t\t\t * @bfqg->entity;\n",
      "\treturn bfq_servive, &bfqg->stats->me(struct bfq_data *pd)\n",
      "\t\t    = &bfq_idle_time),\n",
      "\t\t.seq_init(struct bfq_group(struct b\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.6417\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq_bfqq,\n",
      "\t\t.seq_shook asective lacenced to make queued stard leacure on  beectin bfqg_private = \"bfq.\n",
      "\t * (alled in bfqg_stats->memping(entity = bfq_inid *vp)\n",
      "\t\tservice_time);\n",
      "}\n",
      "\n",
      "/* Free the cmeing r\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4456\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqd, statine, ond ereity.me its be that lowe daret and move.\n",
      " * Move bic used in the came of the long;\n",
      "\tblkcg_policy_blkg_prfill_stat_recut_sempty_update_io_private_bfqd, int be tactic u64 bfqg_stats \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.7436\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqd, stats);\n",
      "\tstruct bfq_data *pd, stats, ith the group *bfqg)\n",
      "{\n",
      "\tbfqg_stat_entityp_tricy_bfq, sheding)\n",
      "{\n",
      "\tstruct bfq_group *bfq_data = &bfqg->entity->service_time(bfq, struct bfq_group *bfqg)\n",
      "{\n",
      "\tstru\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4522\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq = bic_to_blkg(bfqd);\n",
      "\n",
      "\tif (bfqq(bfqd)) = bfqg_stats_update_set_to_blkcg(seq_show = bfqg_stats;\n",
      "\n",
      "\tblkcg_queue *se be its false the ival the prions and the conset of the scher fill be * the cothe bf\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.6300\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tbfqg_stats_update_io_reemoving thas set contitive group asans oot gfp)\n",
      "{\n",
      "\tblkg_stat_add_aunt(stats->idle_time);\n",
      "\tblkg_stat_reset_show_io_show_weight_leacits_update_idling(stats);\n",
      "}\n",
      "\n",
      "void bfqg_\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4924\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg(stats->weight,\n",
      "\t\t.seq_show = bfqg_print_rwstat_recursive);\n",
      "\tblkg_rwstat_add_aux(&to;\n",
      "\tstruct bfq_dequeues(bfqd, bfqq)) {\n",
      "\t\treturn 0;\n",
      "}\n",
      "\n",
      "static struct bfqg_stats_ective = \"bfq.io_queued = bfqg_prin\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.5642\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfq_cpd_weight,\n",
      "\t\t\t\t   struct bfq_group op)\n",
      "{\n",
      "\tstruct bfq_end_wr_async_queued., bfqg_to_bfqgd(blkcg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg = blkg_stat,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name *bfqg).  | Ostruct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.5820\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_to_bfqq->entity->parent);\n",
      "\tblkcg_print_rwstat,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_add(struct bfq_group *bfqq,\n",
      "\t\t\t\t            /netime = \"bfq.io_get_file (unlikely(!bic_update_and;\n",
      "\tstruct bfq_group, stats.s\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2908\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg) {\n",
      "\t\tbfqg;\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static void bfq_find_set_group_bfqq_group(bfqg);\n",
      "\n",
      "\treturn the roofllag amermechux challoc(struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_queue *bfqg, unsigned int offling, and foll\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.6004\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg);\n",
      "\treturn 0;\n",
      "\tunparent = bfqd->root_group;\n",
      "}\n",
      "\n",
      "struct bfq_group, stats.merged);\n",
      "\tblkg_stat_add_aux(&to->avg_queue_size_sum);\n",
      "\tblkg_policy(bfqd);\n",
      "\n",
      "\tblkg_rwstat_add_aux(&stats->merged, &bfqq->ioprio;\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.2163\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bic,\n",
      "\t\t\t                           unsigned lone adde.\n",
      " */\n",
      "static void bfq_bic_changed = bfq_blkg_to_bfqq(entity);\n",
      "}\n",
      "\n",
      "/* @stats->start_group_blkgs(sf, css_to_blkcg(seq_css(sf)-q(bfqq->ioprio);\n",
      "\tstruct \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.9042\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg->queued))\n",
      "{\n",
      "\tu64 stats and moved to the nall be dewing the private the parent belowiven bfqq = bfq_cpd_idling)\n",
      "{\n",
      "\tbfq_init_stat_reset(&stats->queued, false);\n",
      "\tblkg_rwstat_add(&stats;\n",
      "\tif (time);\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.1699\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_and_blkg_get(bfqd->root_group_wait_tive))\n",
      "\tblkg_stat_add_aux(&to->dequeue *sync(bfqd->related with this should cust in bfqg_and_clodx(&stats->avg_queue_size_sum);\n",
      "\tblkg_stat_add(&stats->idle_time)\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4612\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg)\n",
      "{\n",
      "\tblkcg_prfill_sectors(struct bfq_group, stats.wait_time),\n",
      "\t\t.seq64 = bfq_pd_offline - deactivate the ong BFQG_stats_empty_time_recursive\",\n",
      "\t\t.private = offsenfsync_bl\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4815\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg);\n",
      "}\n",
      "\n",
      "static void bfqg_stats_update_cgroup_wait_time = sched_clock();\n",
      "\tstruct bfq_group *bfqg,\n",
      "\t\t\t\t\t\t\\\n",
      "struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfqg_stats *stats.pd) || he queue descendersochedulel the ro\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.8124\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_prfill_rwstat_recursive,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_service, gfp) ||\n",
      "\t    Cinal Public                    bfqg_stats_update_dequeue(struct bfqg_stats_update_idle_time(struct bfqg_stats_clear_empty(s\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.6880\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats_##name);\n",
      "\tblkg_stat_add(&stats->avg_queue_size_recursive,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_merged),\n",
      "\t\t.seq_show = bfqg_print_rwstat,\n",
      "\t.pd_to_bfqgd(blkg))\n",
      "{\n",
      "\tstatic void bfq_group_setup, stats.r#set_\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.8468\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqd: the private hel @bfqq to prin_group.h>\n",
      "#include <linux/ktime, gfp) ||\n",
      "\t   = bfq_group *bfqg, unsigned int op)\n",
      "{\n",
      "\tbfqg_stats_empty(stats))\n",
      "\t\tbfq_reparent_leaf(bfqq);\n",
      "\tu64 that entity\n",
      "\t * request b\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3868\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg);\n",
      "}\n",
      "\n",
      "void bfq_reparent_leaf_entity_set(struct bfq_group *bfqg), blkg_to_bfqg(pd);\n",
      "\tstruct blkg_policy_data *pd)\n",
      "{\n",
      "\tstruct bfq_group *bfqg = pd_to_bfqg(pd);\n",
      "\tstruct bfqg_stats_laged(struct blkcg_po\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.9343\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqgL)) BFQ_IOSCE L's stime BBFQ->weight;\n",
      "\tif (!bfqd->root_group;\n",
      "}\n",
      "\n",
      "static int bfqg_print_rwstat(struct bfq_queue *bfqq need with this blk-cgroup to move references\n",
      " *  Move references the group is no\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3315\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bic->entity_to_bfqq(bio));\n",
      "\tif (time_after64(now, io BFQG_stat_##name(&bfqg->stats);\n",
      "}\n",
      "\n",
      "static void bfqg_stats_##name_entity(bfqd, entity;\n",
      "\n",
      "\tbic {\n",
      "\t\tentity = bfqd->in_stat_recursive_sum(pd_to_bfqg(blkc\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.6419\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg->pd)\n",
      "\t\treturn NULL;\n",
      "\n",
      "\tif (likely(struct bfq_group *bfqg = pd_to_blkg(bfqg), blkcg, bfqg)->private, false);\n",
      "\treturn blkcg_group;\n",
      "\tif (bfqg assomight betein_service_tree(struct bfq_group *bfqg)\n",
      "{\n",
      "\ts\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.7678\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_print_stat_sectors_recursive,\n",
      "\t},\n",
      "\n",
      "{\n",
      "\tblkg_path(bfqd->queue_recursive_sum, val);\n",
      "\treturn blkg_to_blkg(bfqd, bfqg)\n",
      "{\n",
      "\tbfq_deactivate_entity, struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct blkcg_gq *blkg)\n",
      "{\n",
      "\tret\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3651\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bic, val);\n",
      "\n",
      "\tif (!(&bfqg->sched_data)\n",
      "\t\tbfqg_stats_reset(&bfqg->stats, 0);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tbfq_fn\t * bfq_blkg_get (entity.(seq_file *sf, void *v)\n",
      "{\n",
      "\tblkcg_print_blkgs(sf, css_to_blkcg(seq_css(sf)),\n",
      "\t\t\t  bfqg_prfill\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.5115\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqd->lkcg_policy_bfq);\n",
      "\tstruct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfq_bfqq_move(bfqg)->etime);\n",
      "\tblkg_stat_idle_time = stats->start_empty_time))\n",
      "\t\t\tblkg_stat_add(&stats->a\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.7785\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bytes,\n",
      "\t\t\t\t     u64 valing return the address of bfqg_stats_init(&stats->idle_time);\n",
      "\tblkg_stat_reset(&bfqg->stats;\n",
      "\n",
      "\tif (!bfqg)\n",
      "\t\treturn NULL;\n",
      "\t}\n",
      "\n",
      "\tstatic void bfqg_stats_mark_wrwstat_reset(&stats->av\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4622\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg;\n",
      "\tint i;\n",
      "\n",
      "\tbfqq =is stats in the root_group hist so this should be called last used handling references to struct bfq_group *bfqg = pd_to_bfqg(pd);\n",
      "}\n",
      "\n",
      "void bfqg_stats_reset(&bfqg->stats.queued, on\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.8812\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg;\n",
      "\n",
      "\tstruct bfq_group *bfqg, bfqq_bfqq_busy(struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_queue *bfqq,\n",
      "\t\t\t        unsigned stats in path use any\n",
      "\t * the blkg\n",
      " * on news a bfqg and flag of blkg refer the tre\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2099\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats *stats)\n",
      "{\n",
      "\tstruct bfqg_stats *stats)\n",
      "{\n",
      "\tnow_init(&stats->wait_time);\n",
      "\tbfqg_stats_set_start_time(struct bfqg_stats->merged);\n",
      "\tblkg_stat_init(&stats->service_time, gfp) ||\n",
      "\t   struct bfq_group\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.5816\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg, unsigned int ondlens: = bfq_io_show_weight,\n",
      "\t\t\t\t      * Set the blkg is shorter value\n",
      "\t\t * request (mock, entity.\n",
      "\t\t */\n",
      "\t\tif (bfqg_stats_cleaf_entity;\n",
      "\tentity = bfq_deq\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1570\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg,\n",
      "\t\t\t\t\t struct cgroup_waiting = 0;\n",
      "\tbfqg->in_service_queue)\n",
      "\t\tap_rectats_update_io_add(struct bfq_entity *entity)\n",
      "{\n",
      "\tstruct blkg_rwstat_recursive(struct seq_file *sf, voi\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3464\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg->entity.new_weight;\n",
      "\telse if (entity->parentity, ab data scheduler is alke sule being of the\n",
      "\t * addes a, along in guarantee_to_blkgs(sf, css_to_blkcg(seq_css(sf)),\n",
      "\t\t\t  bfq_data *)bfqq->new_weigh\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3130\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg;\n",
      "}\n",
      "\n",
      "void bfq_pd_init(struct bfq_group, stats.\n",
      " * @pd,\n",
      "\t\t\t\t     struct blkcg *blkcg_to_bfqg(blkg);\n",
      "\t\t\t\t/*\n",
      "\t * arent;\n",
      "\n",
      "\treturn bfqg->pd;\n",
      "}\n",
      "\n",
      "void bfq_bfqq_bic_update_cgroup for why refcounting */\n",
      "\tbf\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3240\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg,\n",
      "\t * scheduler lock held.\n",
      "\t *\n",
      "\t * It a blkg don't ght berecs in bfq_entity.new_weight = k1);\n",
      "\n",
      "\tbfqg->ref-;\n",
      "\tstats *stats = bfqq->new_ioprio_class;\n",
      "\t}\n",
      "\tentity->on_stats = &bfqg->stats;\t}\n",
      "\n",
      "void bfq_\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2310\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfq_create_group_hierarchy(struct bfq_group *bfqg, struct bfqg_stats *stats)\n",
      "{\n",
      "\treturn &bfqg->entity.new_weight = cgroup_blkgs(sf, css_to_blkcg(seq_css(sizeof(*bfqg),\n",
      "\t\t\t\t   \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1817\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_policy_data *pd, int of\n",
      " *                                   See moved to the path is been of the instances of the entities.\n",
      " * @st: the group which move from.\n",
      " * @bfqq: the device data structure \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3814\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg *sync_bfqq,\n",
      "\t\t\tstruct blkg_policy_data *pd, int off)\n",
      "{\n",
      "\tstruct blkcg_gq *blkg;\n",
      "\n",
      "\tspin_unlock_irq(&blkcg->lock);\n",
      "}\n",
      "\n",
      "/* BFQ. ITPt start_time, unsigned long)&blkcg_queue_size_time);\n",
      "\tblkg_stat_exit(&\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3414\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg, &blkcg->blkg, &blkcg->entity.prio_changed_fles, sum >9);\n",
      "}\n",
      "\n",
      "void bfqg_stats_set_start_idle_entity(struct bfq_entity *entity = bfq_entity_to_bfqq(bfqd, blkg);\n",
      "\tstruct bfq_group *bfqg) { }\n",
      "void bfq\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3844\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_prfill_rwstat_recursive(struct seq_file *sf,\n",
      "\t\t\t\t      struct bfq_group *bfqg)\n",
      "{\n",
      "\tblkg_rwstat_add_aux(&to->empty_time,\n",
      "\t\t\t           */\n",
      "\tbfq_end_wr_async(struct bfq_entity *entity = &bfqg->stats.q\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2446\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_policy_data *pd)\n",
      "{\n",
      "\tbfq_end_wr_async(struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg, *parent);\n",
      "\t}\n",
      "\n",
      "\treturn bfqg->entity.new_weight (if\n",
      "\t\t\t * critate queues by the root group *bfqg,\n",
      "\t\t\t         \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.5067\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_to_bfqg(pd),\n",
      "\t\t\t\t\t\t\t\t\tbfqq->ioprio = bfqq->new_ioprio_class;\n",
      "\t\t\t/*\n",
      "\t\t * Make short has structh the sore the bfq_log_* functions. We cache through a blkg_lookup in the bfq_log_* functions. We cache\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2660\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bytes, parent);\n",
      "\t\t\t\tbfqg->sched_data = &bfqg->sched_data;\n",
      "}\n",
      "\n",
      "/* print any long new only the following to mo_bfqq_move(bfqd, sort)\n",
      "\t\treturn NULL;\n",
      "\n",
      "\t}\n",
      "\n",
      "void bfqg_stats_reset(&bfqg->stats);\n",
      "}\n",
      "\n",
      "static stru\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1685\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg. And it group is ald gfp) ||\n",
      "\t    blkg_stat_read(&to->service_tree_file *sf,\n",
      "\t\t\t\t      struct bfq_group *bfqg, unsigned int op)\n",
      "{\n",
      "\tblkg_rwstat_ios_merged(struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct blkg_pol\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1876\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats_reset(stats);\n",
      "\tif (bfq_bfqq_move(struct bfq_group *bfqg) { }\n",
      "void bfqg_stats_set_start_empty_time(struct blkcg_policy_data *pd)\n",
      "{\n",
      "\tstruct blkcg *blkcg = css_to_blkcg(css);\n",
      "\tbfqg_stats_update\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.5487\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_lookup performed with bfqg)\n",
      "{\n",
      "\tblkg_rwstat_add(&bfqg->stats, gfp) ||\n",
      "\t    blkg_stat_sectors_recursive(struct seq_file *sf,\n",
      "\t\t\t\t          unsigned long long now;\n",
      "\n",
      "\tif (!bfqg_stats_exections = bfq_e\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4782\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_lookupt avg_queue_size\",\n",
      "\t\t.private = offsetof(struct bfq_group *bfqg, struct bfq_queue *bfqq = bic_to_blkcg(seq_css(sf)),\n",
      "\t\t\t  bfqg_prfill_avg_queue_size_samples, &from->avg_queue_size_samples, g\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1880\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfq_io_set_weight_legacy,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.time - start_time,\n",
      "\t\t\t\t  unsigned int op) {\n",
      "\t\t\t\tstruct blkg_stat_add_aux(&to->idle_time, start_tie.erame)))\n",
      "\t\tblkg_rwstat_exit(&stats->idle_time);\n",
      "\tblkg_\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.6837\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_parent(struct bfq_group *bfqg = pd_to_bfqg(blkg_to_pd(blkg, &blkcg_policy_bfq));\n",
      "}\n",
      "\n",
      "void bfq_pd_free(struct seq_file *sf,\n",
      "\t\t\t\t\t\tstruct bfq_group *bfqg_parent(ps);\n",
      "\tstruct bfq_group *bfqg = pd_to_b\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3470\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_to_blkg(pd);\n",
      "\t/*\n",
      "\t * Update flags long now = sched_clock();\n",
      "\tif (unlikely(!bfqg))\n",
      "\t\tbfqg->sched_data != &parent->files,\n",
      "\n",
      "\t.cpd_free_fn\t\t= bfq_cpd_init,\n",
      "\t.cpd_bind_fn\t           bfqg_and_blkg_fq_fi\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1042\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_print_rwstat_recursive,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.avg_queue_size\",\n",
      "\t\t.seq_show = bfqg_print_rwstat_recursive,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_wait_time\",\n",
      "\t\t.private = offsetof(struct bfq_group, entity);\n",
      "\tent\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3068\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_prfill_stat,\n",
      "\t.cpd_alloc(gfp_t gfp) {\n",
      "\t\tbfqg = bfqd->root_group;\n",
      "\tservice_tree(entity, false);\n",
      "\tbfq_queue_size(struct bfq_group *bfqg = blkg_to_bfqg(blkg);\n",
      "\treturn NULL;\n",
      "\tif (time_after64(now, sta\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4415\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg, struct bfq_group *bfqg, unsigned int op)\n",
      "{\n",
      "\tblkg_rwstat_add_aux(&to->avg_queue_size_samples);\n",
      "\tblkg_rwstat_add_aux(&to->dequeue, &from->avg_queue_size_samples);\n",
      "\tblkg_rwstat_exit(&bfqg->stats.mer\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3085\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_to_bfqgd(blkcg);\n",
      "\tstruct blkcg *blkcg = css_to_blkcg(seq_css(sf)), blkg_to_bfqg(pd);\n",
      "\n",
      "\tif (bfqg_stats_mark_empty(stats))\n",
      "\t\treturn;\n",
      "\n",
      "\tif (ve any long new one.  Avoid its are comples of the bfq_log_\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4182\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg = bfq_group, stats.time),\n",
      "\t\t.seq_show = bfqg_print_avg_queue_size_sum, 1);\n",
      "}\n",
      "\n",
      "static int bfqg_print_stat_sectors, &blkcg_policy_bfq, seq_cft(sf)->private, false);\n",
      "\treturn bfqg;\n",
      "}\n",
      "\n",
      "/**\n",
      " * bfq_flush\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3035\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfqg_stats *to, struct bfq_io_cq *bic, struct bio *bio)\n",
      "{\n",
      "\tstruct bfq_group *bfqg, unsigned long long now, we asynchrong\n",
      "\t * to to a data structures relates long now = sched_clock();\n",
      "\tbfqg_stats_update\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2708\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqd->lock held ver vervow it mis move.\n",
      " * @bfqq to @bfqg\n",
      " * time here.\n",
      " * @bfqd: the scheduler lock held val > BFQ_MAX_WEIGHT)\n",
      "\t\treturn;\n",
      "\n",
      "\t/*\n",
      "\t * NULL\n",
      "\t\t\t\t   * time here, at the prio_changed flong lon\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1327\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_lookup(blkcg);\n",
      "\n",
      "\tif (unlikely(!bfqg)) *\n",
      "\t * the serviced the parent of a blkg_wait_time\",\n",
      "\t\t.private = offsetof(struct bfqg_stats *stats)\n",
      "{\n",
      "\tblkg_rwstat_add(&bfqg->stats);\n",
      "\t}\n",
      "\n",
      "\tbfqg_and_blkg_get(s\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2065\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats_empty,\n",
      "};\n",
      "\n",
      "struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfqg_stats *stats *stats)\n",
      "{\n",
      "\tblkg_rwstat_add_aux(&to->empty_time, &from->group_wait_time);\n",
      "\tblkg_stat_exit(&stats->merged);\n",
      "\tblkg_stat_exit(&stat\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2072\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_lookup performed with bfqd->lock impling\n",
      "\t\t * (bfqd->lock);\n",
      "\n",
      "\tif (!bfqg_stats_mark_##name(struct bfq_group *bfqg, struct bfq_queue *bfqq,\n",
      "\t\t       struct bfq_group *bfqg,\n",
      "\t\t\t\t\t nep_init,\n",
      "\t\t\t\t     \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4271\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg->bfqd)\n",
      "\t\treturn NULL;\n",
      "\n",
      "\treturn bfqg;\n",
      "}\n",
      "\n",
      "/**\n",
      " * bfq_bic_update_cgroup in the following with the scheduler on guaranteed this bfqd->lock is being added to may be reases to readily may data for the i\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1199\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg) { }\n",
      "void bfqg_stats_update_io_merged(struct bfq_group *bfqg) { }\n",
      "void bfqg_stats_add(struct bfq_group *bfqg) { }\n",
      "void bfqg_stats_set_start_empty(stats);\n",
      "}\n",
      "\n",
      "/* This should be called with the sched\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1813\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats *stats)\n",
      "{\n",
      "\tunsigned long now = sched_cond_empty_time);\n",
      "\tbfqg_stats_inum(bfqq_entity_to_bfqq(entity);\n",
      "\n",
      "\tentity->sched_data = &bfqg->sched_data.in_service_time = sched_clock();\n",
      "}\n",
      "\n",
      "/*\n",
      " * bfq_bf\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.5340\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq_busy, then bfq_bic_change_cgroup(struct bfq_group *bfqg, unsigned int op) { }\n",
      "void bfq_bfqq_move(struct blkg_policy_bfq,\n",
      "\t\t\t  uint64_t io_start_time, puappor (bic the root group and its parent nev\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3423\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "biced = blkg_prfill_sectors, &blkcg_policy_bfq,\n",
      "\t\t.seq_show = bfqg_print_rwstat,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_merged\",\n",
      "\t\t.private = offsetof(struct bfq_group, stats.time),\n",
      "\t\t.seq_show = blkg_print_stat_rec\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.6152\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg, stats.service_entity)\n",
      "\t\tbfq_reparent_leaf_entity(bfqd, bfqg, st);\n",
      "\t}\n",
      "\n",
      "\t__bfq_deactivate_entity(fnly of the scheduler lock held. */\n",
      "static void bfqg_stats_update_cgroup(struct bfq_group *bfqg)\n",
      "{\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      "1.00000e-02 *\n",
      "  9.9228\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg->rq_posparent;\n",
      "\tentity->sched_data = &bfqg->stats;\n",
      "\tunsigned int op)\n",
      "{\n",
      "\tstruct bfq_group *bfqg\n",
      ", struct bfqg_stats *stats)\t\\\n",
      "{\t\t\t\t\t\t\t\t\\\n",
      "\treturn;\n",
      "\n",
      "\tblkg_stat_add(&stats->wait_time);\n",
      "\tblkg_stat_exit\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2414\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats.merged, gfp) {\n",
      "\t\tkfree(bfqg);\n",
      "}\n",
      "\n",
      "void bfq_bfqq_move(struct bfqg_stats *stats)\n",
      "{\n",
      "\tbfq_end_wr_async(struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg = pd_to_bfqg(pd);\n",
      "\n",
      "\tbfqg->ref_t = offsetof\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2301\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tstruct bfq_entity *entity)\n",
      "{\n",
      "\tstruct blkg_policy_data *pd)\n",
      "{\n",
      "\tstruct bfq_entity *entity = &bfqg->entity;\n",
      "\tbfqg;\n",
      "\n",
      "\tentity->parent = parent->stats, while we\n",
      "\t */\n",
      "\tint ignow = blkg_print_to_bfqg(\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1017\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfq_create_group_hierars_ared\tent = bfqq->new_ioprio;\n",
      "\t\tbfqq->ioprio = bfqq->new_ioprio;\n",
      "\t\tif (bfqgd)\n",
      "\t\tval = bfqg_print_rwstat,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_merged_recursive\",\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4500\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg = pd_to_bfqgd(cpd);\n",
      "\tstruct bfq_group *bfqg = pd_to_bfqg(pd);\n",
      "\tstruct bfq_entity *entity = bfqd->root_group;\n",
      "\tif (async_bfqq = bic_to_bfqq(bic, 1);\n",
      "\tstruct bfq_group *bfqg = blkg_to_bfqg(blkg);\n",
      "\ts\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2693\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\t/* stats in the file is used */\n",
      "\tblkg_rwstat_exit(&stats->avg_queue_size_sum);\n",
      "\tblkg_rwstat_init(&stats->idle_time);\n",
      "\tblkg_stat_add_aux(&to->idle_time);\n",
      "\tblkg_stat_reset(&stats->idle_time);\n",
      "\tb\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2899\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats *stats)\n",
      "{\n",
      "\tstruct blkg_policy_data *pd, int off)\n",
      "{\n",
      "\tstruct bfq_io_cq *bic, struct bfq_group_data *bfqgd)\n",
      "{\n",
      "\tstruct bfq_group_data *blicy data strumiy be the bfq_group hierarchy\n",
      " * by allowin\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1903\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats *stats, gqd, struct bfq_data *bfqd = bic_to_bfqd(bic, bio_start_time))\n",
      "\t\tkfree(bfqg);\n",
      "\t}\n",
      "\n",
      "\t/* see comments in bfq_bic_update_cgroup on guaranteeing the unsigned long for has takend may be mo\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1342\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_to completion_storme)\t\t  &blkcg_policy_bfq,\n",
      "\t\t.seq_show = bfqg_print_stat_sectors,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.sectors_recursive\",\n",
      "\t\t.seq_show = blkg_print_stat_sectors_recursive,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1708\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats_end_empty_time,\n",
      "\t\t\t  uint64_t io_start_time - start_time);\n",
      "\tbfqg_stats_end_empty_time))\n",
      "\t\tblkg_stat_add_aux(&to->idle_time, gfp) ||\n",
      "\t    blkg_rwstat_init(&stats->merged);\n",
      "\tblkg_rwstat_add_au\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3482\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_to_blkg(bfqg));\n",
      "}\n",
      "\n",
      "void bfq_io_set_weight_legacy(struct bfqg_stats *stats)\t\t\\\n",
      "{\t\t\t\t\t\t\t\t\t\t\t\t\\\n",
      "\treturn bfq_io_show_weight,\n",
      "\t\t.write_entity(struct bfq_group *bfqg,  struct bfqg_stats *stats)\n",
      "{\n",
      "\tblkg_\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.5558\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg->pd;\n",
      "}\n",
      "\n",
      "void bfq_bfqq_move(struct bfq_group */*\n",
      "\t\t\t * The blkg_[rw]stat_recursive(struct seq_file *sf,\n",
      "\t\t\t\t\t struct bfq_group *bfqg = pd_to_bfqg(pd);\n",
      "\tstruct bfq_entity *entity) {\n",
      "\t\tbfqg->entity.n\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1166\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg);\n",
      "}\n",
      "\n",
      "void bfqg_stats_update_io_remove(struct bfq_group *bfqg = pd_to_bfqg(pd);\n",
      "\tstruct bfq_group *bfqg = pd_to_bfqg(blkg);\n",
      "\n",
      "\tif (!bfqg)\n",
      "\t\treturn ret;\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int bfqg_print_stat();\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2840\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_lookup_bfqgd = blkcg_to_bfqgd(struct bfq_group *bfqg)\n",
      "{\n",
      "\tblkg_weight;\n",
      "\tentity->oreact, and to the following\n",
      "\t * det\n",
      " * request in parent its this bic, and instances.\n",
      " */\n",
      "#include <L is used in the\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1947\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bqd,\n",
      "\t\t\t\t     struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct blkg_policy_data *pd)\n",
      "{\n",
      "\tstruct blkcg *blkcg = css_to_blkcg(seq_css(sf)),\n",
      "\t\t\t  bfqg_prfill_stat,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_service antd beset any more.\n",
      "\t\t\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3188\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_print_stat_bytes,\n",
      "\t\t\t\t loff_t off)\n",
      "{\n",
      "\tstruct bfq_group *curr_bfqg)\n",
      "{\n",
      "\tbfqg->ref--;\n",
      "\n",
      "\tif (bfqg->ref->mere_entity(struct bfq_group *bfqg,\n",
      "\t\t\t\t      blkg_rwstat_recursive_sum(pd_to_blkkg, which\n",
      "\t * t\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1665\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_prfill_avg_queue_size_samples, 1);\n",
      "\tbfqg_stats_waiting(stats);\n",
      "}\n",
      "\n",
      "void bfq_pd_reset_stats(struct bfq_group *bfqg)\n",
      "{\n",
      "\tbfqg_put(bfqg);\n",
      "\t}\n",
      "\tentity->orig_weight = entity->new_weight = d->weight;\n",
      "\tif (\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1668\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_to_bfqg(blkg);\n",
      "\tsep_flags {\n",
      "\tBFQG_stats_mark_waiting(stats);\n",
      "}\n",
      "\n",
      "/*/\n",
      "static struct bfq_group *bfq_creative_sum(pd->blkg. After we\n",
      "\t * all the queue to move to the following to this group before\n",
      "\t *\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3220\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_print_rwstat_init(&stats->merged, gfp) ||\n",
      "\t      blkg_rwstat_init(&stats->wait_time);\n",
      "\tblkg_stat_exit(&stats->service_time, gfp) ||\n",
      "\t      blkg_rwstat_init(&stats->empty_time);\n",
      "}\n",
      "\n",
      "/*\n",
      " * Traveld. *\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2073\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_rwstat_recursive,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_queued\",\n",
      "\t\t.private = offsetof(struct bfq_data *)bfqg->bfqd)->in_service_queue, &blkcg_policy_bfq,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t  seq_cft(sflate, false);\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1308\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_rwstat_reset(&stats->avg_queue_size_samples);\n",
      "\tblkg_rwstat_reset(&stats->avg_queue_size_samples);\n",
      "\tblkg_rwstat_exit(&stats->service_time, op,\n",
      "\t\t\t\t   offlags | = \"bfq.io_queued_recursive\",\n",
      "\t\t.priva\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1340\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_tightly(blkg)->queue))\n",
      "\t\tblkg_stat_reset(&stats->group_wait_time);\n",
      "\tblkg_stat_reset(&stats->time);\n",
      "\tblkg_stat_reset(&stats->avg_queue_size_samples);\n",
      "\tblkg_stat_reset(&stats->avg_queue_size_samples\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2428\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats_setof(struct bfqg_stats *stats)\n",
      "{\n",
      "\tunsigned int op) {}\n",
      "\n",
      "void bfqg_stats_update_dequeue(struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_entity *entity = bfqg->entity;\n",
      "\tentity\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4659\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg, &blkcg_policy_bfq));\n",
      "}\n",
      "\n",
      "/**\n",
      " * bfq_fl cuse in bfqq it makes sure that sightly more.\n",
      " * @bfqq: the queue descriptor.\n",
      " * @bfqq to @bfqg, proget(off), NULL;\n",
      "}\n",
      "\n",
      "static int bfqg_print_stat(struct seq_\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2423\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats_idling,\n",
      "\tBFQG_stats_set_stat_recursive(struct seq_file *sf, void *v)\n",
      "{\n",
      "\tstruct blkg_rwstata *blkcg = css_to_blkcg(seq_show = bfqg_print_stat,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_queued.h>\n",
      "#include <lin\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4579\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_and_blkg_get perturn ret;\n",
      "\n",
      "\tret = 0;\n",
      "\tif (!bfqgd->my_data *cpd)\n",
      "{\n",
      "\tstruct bfq_group *bfqg = blkg_to_policy_data *pd)\n",
      "{\n",
      "\tstruct blkcg_gq *blkg;\n",
      "\n",
      "\tlist_for_each_entry(blkg, &blkcg->blkg_list, blkcg_\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3449\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfq_queue *bfqq to pin down\n",
      "\t * reasocher following\n",
      "\t * reasocherserences arent, in that the root group */\n",
      "\tentity->sched_data = &bfqg->sched_data;\n",
      "}\n",
      "\n",
      "static int bfqg_print_stat_sectors_recursive, &blk\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2971\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_rwstat_add(&stats->avg_queue_size(struct bfq_data *bfqd,\n",
      "\t\t\t\t\\\n",
      "\n",
      "struct bfq_entity *entity);\n",
      "\n",
      "\t\tif (time = sched_clock();\n",
      "\tbfqg_stats_reset(&bfqg->stats,\n",
      "};\n",
      "\n",
      "struct bfq_group *bfqg) { }\n",
      "void bfqg_s\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4726\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfq_queue d.seq_show = bfqg_print_rwstat,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_wait_time\",\n",
      "\t\t.private = offsetof(struct bfq_group, stats.service, &from)\n",
      "\t\treturn;\n",
      "\n",
      "\t/*\n",
      "\t\t * service_entity) stor.\n",
      " *   The anconsist\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3329\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats *stats)\t\\\n",
      "{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\\n",
      "\tstats->flags {\n",
      "\tBFQG_stats *sf, struct bfq_group *bfqg) { }\n",
      "void bfqg_stats_update_io_remove(struct bfq_group *bfqg) { }\n",
      "\n",
      "v\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4957\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqd->lock is being already marked expos. IOOs counts so the following\n",
      "\t * reasons. Operations gfp lock group is fore, no blkcg op)\n",
      "\t\tbfqg->sched_data;\n",
      "\tbfqg->active_entities - move.\n",
      " * @blkcg: the bfq\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3024\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_to_bfqg(blkg);\n",
      "\treturn bfqg;\n",
      "}\n",
      "\n",
      "/**\n",
      " * bfq_flush_idle_tree - deactivate the\n",
      "\t * blkg. This device data structure with the execution of the following functions.\n",
      "\t *\n",
      "\t * Finally, async_bfqq, async_b\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2476\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bic_set_group */\n",
      "\t\treturn;\n",
      "\n",
      "\tbfq_end_wr_async_queues(bfqd, bfqg);\n",
      "\t}\n",
      "\treturn __blkg_prfill_sectors(struct seq_file *sf, struct bfq_group *bfqg;\n",
      "\n",
      "\tbfqg = __bfq_bic_change_cgroup(struct bfq_data *bfqd, a\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2230\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg, stats.service_trees assorie))\n",
      "\t\tentity.new_weight is corresponed async_bfqq = nose);\n",
      "\treturn __blkg_prfill_rwstat,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_wait_time_recursive\",\n",
      "\t\t.private = (unsigned long)&blkc\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3455\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg. After with the request queue the hope that bfqg is usleary of nows the root group */\n",
      "\tentity->sched_data = &bfqg->sched_data;\n",
      "}\n",
      "\n",
      "void bfq_cpd_free(struct bfq_group *bfqg) { }\n",
      "void bfq_set_start_g\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2297\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_parent(!bfqg_print_rwstat_recursive,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.weight\",\n",
      "\t\t.freatimy = bfqq->new_ioprio_class;\n",
      "\n",
      "\t/* If bfqq is explick, and update it from its in bfq_bic_update_cgroup for we new valus,\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2414\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg->my_entity = entity);\n",
      "\t\tif (time_after64(io_start_time))\n",
      "\t\tblkg_rwstat_add(&bfqg->stats.avg_queue_size, &blkcg_policy_bfq,\n",
      "\t\t\t  seq_cft(sf)->private, false);\n",
      "\n",
      "\t\tif (entity->weight = entity->sched_\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1682\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bic, struct bfq_data *bfqd,\n",
      "\t\t\t\t\t struct blkcg_gq *bfqg)\n",
      "{\n",
      "\treturn pd ? container_of(gto_cpd(blkcg, &blkcg->blkg_list, blkcg_node(sizeof(*bfqg), bfqg->blkg_path, sizeof(bfqg);\n",
      "\n",
      "\tblkg_get(bfqg_to_blkg(b\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1678\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg = bfqd->root_group;\n",
      "\tseq_prin_service_tree(entity).plA_BESSTrin_bfqq_expire(bfqd, bfqq);\n",
      "\t\tbfq_activate_bfqq(bic, 0);\n",
      "\tstruct bfq_group *bfqg = blkg_to_bfqg(blkg);\n",
      "\treturn NULL;\n",
      "\n",
      "\tif (bfqg_stats_s\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2815\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg = pd_to_bfqg(pd);\n",
      "\tstruct bfq_queue (entity->sched_data = &bfqg->sched_data;\n",
      "}\n",
      "\n",
      "static ssize_fn\t\t= bfq_cpd_lookup, bfqg->my_entity;\n",
      "\tentity->sched_data = &bfqg->sched_data;\n",
      "\treturn __bfq_bic_chate\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2208\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfq_get_group *bfqg = pd_to_bfqg(pd);\n",
      "\n",
      "\tbfqg_stats_xfer_dead(struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_group *parent)\n",
      "{\n",
      "\tstruct bfq_data *bfqd,\n",
      "\t\t\t\t     struct bfq_group *bfqg = pd_to_bfqq(entity);\n",
      "\n",
      "\tbfqg \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2679\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq = bfqgd);\n",
      "\t}\n",
      "\tbfq_end_wr_async_queue *bfqg) { }\n",
      "void bfqg_stats_set_show_weight(struct seq_file *sf, void *v)\n",
      "{\n",
      "\tstruct bfq_data *bfqd = bfqq->entity;\n",
      "\t\tif (entity->parentiy on = bfqg->sched_data.\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3044\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg = pd_to_bfqg(pd);\n",
      "\tstruct bfq_entity *entity = &bfqg->stats;\n",
      "\n",
      "\tif (bfqg->ref_t = serial_nr)\n",
      "#return;\n",
      "\n",
      "\tstats->start_group_wait_time = sched_clock();\n",
      "\tserial_nr = bio_blk\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3178\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats_update_group_wait_time(struct bfq_group *bfqg, unsigned int op)\n",
      "{\n",
      "\tblkg_rwstat_exit(&stats->wait_time);\n",
      "\tblkg_stat_reset(&stats->service_time);\n",
      "\tblkg_stat_reset(&stats->wait_time);\n",
      "\tblkg_sta\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2568\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_print_rwstat_recursive, &blkcg_policy_bfq, seq_cft(sf)->private, false);\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int bfqg_parent(bfqg);\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static u64 bfqg_prfill_rwstat_recursive(struct seq_file *sf,\n",
      "\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3206\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_prfill_sectors,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_service_bytes\",\n",
      "\t\t.private = offsetof(struct bfqg_stats *avg_queue_size, &blkcg_policy_bfq,\n",
      "\t\t\t  seq_cft(sf)->private, false);\n",
      "\telse if (entity->on_st)\n",
      "\t\tb\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2957\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg, gfp) { }\n",
      "\n",
      "stats->start_empty_time = sched_clock();\n",
      "\tbfqg_stats_exit(struct blkg_policy_data *pd)\n",
      "{\n",
      "\tstruct bfqg_stats *stats = &bfqg->stats;\n",
      "\n",
      "\tif (bfqg_stats_update_dequeue(struct bfq_entity *ent\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1856\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkcg_policy_bfq,\n",
      "\t\t\t      now - stats->start_idle_time, &from->avg_queue_size_sum);\n",
      "\tblkg_stat_exit(&stats->avg_queue_size_samplersBze_sempty_time);\n",
      "}\n",
      "\n",
      "/*\n",
      " * Transfer @bfqg.\n",
      " * @bfqd: the service tree\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.5179\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_get(bfqg);\n",
      "\t\t\tif (!parent)\n",
      "\t\t\t\tparent = bfqg_parent(bfqg);\n",
      "\t}\n",
      "\tentity->parent = bfqg->my_entity;\n",
      "\tentity->we_queue */\n",
      "#Lice *stats)) {\n",
      "\t\t\tbit(struct bfq_group, stats.time),\n",
      "\t\t.seq_show = bfqg_prin\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2993\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_legacy(of), NULL,\n",
      "\t\t\t\t\t   * the consistent blkg, which\n",
      "\t * request in parent group in bfqg_and_blkg_get perfort may happen that it will be peed by to this group hooks.\n",
      " */\n",
      "\n",
      "void bfq_init_entity(st\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2868\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_to_blkg(bfqg));\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void bfqg_stats_set_start_empty_time(struct bfq_sbt_time, &from->dequeue);\n",
      "\tblkg_stat_add_aux(&to->group_wait_time,\n",
      "\t\t\t\t      now - stats->start_idle_time))\n",
      "\t\tblkg_stat_add(&bfq\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4156\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_print_stat_ios_recursive(struct seq_file *sf, void *v)\n",
      "{\n",
      "\tblkcg_print_blkgs(sf, css_to_blkcg(seq_css(sf)),\n",
      "\t\t\t\t  bfqg_prfill_stat_recursive(struct seq_file *sf,\n",
      "\t\t\t\t   now - stats->start_idle_time\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.4200\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_stats *stats)\n",
      "{\n",
      "\tblkg_get(bfqg_to_blkg(bfqg));\n",
      "}\n",
      "\n",
      "void bfq_pd_reset_stats(struct blkg_policy_data *pd,\n",
      " *\t         structive after no the parent of a bfq_group\n",
      " * assignment, and (2) bfqd->lock is\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1474\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_to_bfqg(blkg);\n",
      "\treturn NULL;\n",
      "}\n",
      "\n",
      "struct bfq_group *parent;\n",
      "\n",
      "\tif (!bfqg)\n",
      "\t\treturn NULL;\n",
      "\n",
      "\tif (!bfqg_stats_update_idle_time(struct bfqg_stats *stats)\t\\\n",
      "{\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\\n",
      "\treturn;\n",
      "\n",
      "\tspin_lock_irqsa\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3407\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg, st) : NULL;\n",
      "\n",
      "\t/*\n",
      "\t * Update after\n",
      "\t * in valved blk-cgroup to move to.\n",
      " */\n",
      "static void bfqg_stats_update_io_merged(struct bfq_group *bfq_group_data, pd) : NULL;\n",
      "}\n",
      "\n",
      "static int bfqg_stats_update_id\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1905\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfq_queue *bfqq = bfq_entity_to_bfqq(entity);\n",
      "\n",
      "\tentity->weight = entity->new_weight;\n",
      "\tif (bfqq->binding this\n",
      "\t\t\t * flag use, them\n",
      " * stats cause dangling references houe data structure with the req_ser\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1306\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfq_flush_idle_time),\n",
      "\t\t.seq_show = bfqg_print_rwstat_recursive,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.io_service_time\",\n",
      "\t\t.private = offsetof(struct bfq_group, stats.wait_time),\n",
      "\t\t.seq_show = bfqg_print_stat,\n",
      "\t\t\t  &b\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1612\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_to_blkg(bfqg)->q->queue_lock);\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int bfqg_print_rwstat_recursive(struct seq_file *sf, void *v)\n",
      "{\n",
      "\tstruct bfq_group *bfqg)\n",
      "{\n",
      "\tbfqg->ref++;\n",
      "}\n",
      "\n",
      "void bfq_end_wr_async(struct bfq_gr\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1529\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkg_to_bfqgd(blkcg);\n",
      "\tunsigned int val = 0;\n",
      "\n",
      "\tif (bfqg->sched_data = &bfqg->sched_data;\n",
      "}\n",
      "\n",
      "static u64 bfqg_prfill_avg_queue_size *parent(struct bfq_group *bfqg)\n",
      "{\n",
      "\tstruct bfq_group *bfqg = pd_to_bfqg(\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1873\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq_bfqq, async_bfqq->reft;\n",
      "\n",
      "\tseq_fn\t= bfq_cpd_init,\n",
      "\t.cpd_init_fn\t * On &pd;\n",
      "\t\tiG\n",
      "\t * protected from it and then blk-cgroup before\n",
      "\t * deactivating the consistent, while we\n",
      "\t * are holding bfqd->lock\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2142\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "blkcg_legacy, frated = bfqg->my_entity;\n",
      "\tentity->sched_data = &bfqg->sched_data;\n",
      "}\n",
      "\n",
      "static void bfqg_stats_waiting(stats);\n",
      "}\n",
      "\n",
      "/* This should be called with the scheduler is attached with the scheduler \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2197\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg,\n",
      "\t\t\t\t   of bfqg->entity.new_weight = (unsigned long)&blkcg_policy_bfq,\n",
      "\t\t\t      now - stats->group_wait_time))\n",
      "\t\tblkg_stat_add(&stats->service_tree *st;\n",
      "\tstruct bfq_group *bfqg, unsigned int op)\n",
      "{\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2501\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq_group(struct bfq_data *bfqd,\n",
      "\t\t\t\t\t struct blkcg_policy_bfq,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\\n",
      "BFQG_FLAG_FNS\n",
      "\n",
      "/* This sure statics will be set, the references\n",
      "\t * been obtained through this\n",
      "\t * bfqg itself need\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1430\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq_group_data = &bfqg->sched_data)\n",
      "\t\t\tbfq_bfqq_move(bfqd, bfqq, bfqd->root_group);\n",
      "}\n",
      "\n",
      "/**\n",
      " * bfq_reparent_active_entities - move to the path of the code.\n",
      "\t\t\t */\n",
      "\t\t\tsep_from->avg_queue_size_samples,\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1399\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg_to_blkg(bfqg)->q->queue;\n",
      "\tif (!bfqg)\n",
      "\t\treturn NULL;\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int bfqg_stats *stats = bfqq->new_ioprio_class;\n",
      "\tentity->on_st)\n",
      "\t\tbfq_put_idle_entity(entity) {\n",
      "\t\tbfqg = bfqd->root_group;\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.3187\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq == bfq_entity_to_bfqq(entity);\n",
      "\n",
      "\tentity->weight = entity->new_weight;\n",
      "\tentity->fimq_bic_change_cgroup - move @bic to @cgroup.\n",
      " * @entity: the add terminate, false);\n",
      "\telse if (in the bfq_log_* func\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1417\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq *bic, struct bfq_group *pblkg)\n",
      "{\n",
      "\tstruct bfq_pd_reset_stats_fn\t\t= bfq_pd_free,\n",
      "\t.pd_recursive,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.name = \"bfq.weight\",\n",
      "\t\t.flags = CFTYPE_NOT_ON_ROOT,\n",
      "\t\t.seq_show = bfqg_print_stat,\n",
      "\t},\n",
      "\t{\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2273\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq = bfq_entity_to_bfqq(entity);\n",
      "\n",
      "\tbfq_bfqq_move(bfqd, bfqq, false, false);\n",
      "\telse if (entity\n",
      "\t\t * to returns a fully consistent blkg data we may held for\n",
      "\t * protects the lookup\n",
      " * time here, at the \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.1522\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqq_group(struct bfq_queue *bfqq,\n",
      "\t\t   struct bfq_group *bfq_find_set_policy_data *pd)\n",
      "{\n",
      "\tstruct bfq_entity *group_entity = bfqq->entity.parent;\n",
      "\n",
      "\treturn group_entity ? conting a lock is reactivate an\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2780\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg->stats);\n",
      "\tblkg_stat_exit(&stats->queued));\n",
      "\tblkg_stat_add_aux(&to->dequeue, &from->avg_queue_size_t bfq_io_set_weight(&stats->avg_queue_size_samples))\n",
      "\t\tbfq_reparent_leaf_entity(bfqd, bfqq);\n",
      "\t\t\tbf\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 0.2536\n",
      "[torch.FloatTensor of size 1]\n",
      " \n",
      "\n",
      "bfqg->stats_waiting = 0,\n",
      "\tBFQG_stats_empty,\n",
      "};\n",
      "\n",
      "#define BFQG_FLAG_FNS(name)\t\t\t\t\t\\\n",
      "static struct bfq_group *bfqg = pd_to_bfqg(pd);\n",
      "\tstruct bfq_group *bfqg = pd_to_bfqg(btree, of striged conged condely u\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e8f7062737fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j]\n",
    "        y,hidden = model(x,hidden)\n",
    "        loss += loss_func(y,y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
